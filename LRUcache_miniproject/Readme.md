# LRU cache

![LRU cache](https://github.com/pranavdave893/Leetcode/blob/master/LRUcache_miniproject/0_fOwBd3z0XtHh7WN1.png)

## Original problem link : https://leetcode.com/problems/lru-cache/discuss/?orderBy=recent_activity


### One can implement this with Ordereddict too as mentioned here : https://www.kunxi.org/blog/2014/05/lru-cache-in-python, but if they ask you to implement without using any func tools To use double linked list and hash table is the best idea. 

### cache_list.tail returns the most recently used key and cache_list.head returns the least recently used key. 
